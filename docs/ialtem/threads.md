# Programmation concurrente: Mieux utiliser le processeur üòâ

## Contexte

### Environnement monoprocesseur

**Monoprocesseur = 1 coeur physique**

**Un processus = un programme en cours d'ex√©cution**

- Chaque processus s'ex√©cute de mani√®re isol√©e (pas de partage de contexte ou de m√©moire entre les processus). Autres m√©canismes de communications comme les signaux, les tuyaux, les zones partag√©es ...

- Le processeur ex√©cute un processus √† la fois.

Les environnements monoprocesseur datent des premiers ordinateurs.

- En attribuant des priorit√©s diff√©rentes *(haute et basse)* aux processus qui partagent un m√™me processeur, le syst√®me d'exploitation donne l'impression que ces processus s'ex√©cutent en parall√®le, m√™me si ce n'est pas le cas.

- 1 processeur physique peut avoir des <span class="span-hightlight">processeurs logiques</span> ou coeurs logiques. Ils lui permettant de faire du traitement parall√®le qui dans une certaine mesure est limit√©.

Le besoin de calcul intense et la limite mat√©riel du  **silicium (Si)** ont men√© √† l'option des multiprocesseurs pour accro√Ætre la puissance d'une machine.

#### Et si on faisait un peu d'histoire üòé

!!! info
    .... Un autre facteur important qui influe directement sur la puissance de calcul des microprocesseurs est la vitesse de calcul. Les premiers microprocesseurs fonctionnaient avec une fr√©quence de travail de l‚Äôordre de quelques centaines de milliers de cycles par seconde. La vitesse de calcul des instructions est un multiple du nombre de cycles par seconde. Aujourd‚Äôhui, la fr√©quence de travail des microprocesseurs est de l‚Äôordre des 4 GHz (4 milliards de cycles par seconde). D√©passer cette fr√©quence semble difficile, l‚Äôaugmentation de la fr√©quence des microprocesseurs stagne depuis plus ann√©es. La raison est simple, elle est √† chercher du c√¥t√© de la mati√®re premi√®re utilis√©e pour fabriquer les composants : le silicium. Le silicium est un semi-conducteur facile √† se procurer, il est le troisi√®me √©l√©ment le plus abondant sur terre. Les caract√©ristiques du silicium font qu‚Äôil est difficile de franchir les fr√©quences, contrairement √† d‚Äôautres semi-conducteurs tels que l‚Äôars√©niure de Gallium. Cependant, ils sont plus difficiles √† concevoir et l‚Äôapprovisionnement en mati√®re premi√®re est plus compliqu√© que le silicium. C‚Äôest pour cette raison que l‚Äôindustrie continue √† utiliser le silicium comme semi-conducteur de base avec les inconv√©nients inh√©rents √† cet √©l√©ment chimique. De plus, dans le cas du silicium, les pertes √©nerg√©tiques commencent √† ne plus √™tre lin√©aires lorsque la fr√©quence de travail d√©passe 1 GHz. Par cons√©quent, l‚Äôaccroissement de la fr√©quence engendre des pertes √©nerg√©tiques li√©es plus au silicium qu‚Äôau traitement de l‚Äôinformation.

    ![Silicium](../img/silicium.jpg){:width="30%" align=left}
    Pour rappel, un microprocesseur ne consomme de l‚Äô√©nergie que lorsqu‚Äôil traite de l‚Äôinformation, cette consommation √©tant provoqu√©e par les changements d‚Äô√©tat des transistors dans le microprocesseur. Un microprocesseur qui ne traite pas d‚Äôinformation ne consomme pas (ou tr√®s peu). Un autre facteur qui a permis l‚Äôaugmentation de la puissance de calcul est la diminution de la tension √©lectrique de travail. Pour limiter les temps de commutation des transistors d‚Äôun √©tat vers son oppos√©, les microprocesseurs ne reconnaissent que deux √©tats (d‚Äôo√π la logique binaire). La tension est pass√©e de 5 V √† environ 1 V. Descendre en dessous du volt est difficile, les caract√©ristiques des transistors rendent difficile d‚Äôavoir des √©tats bien d√©finis n√©cessaires √† la logique binaire.
    <br>
    Au final, la conclusion est simple. Les limites en termes de densit√©, de fr√©quence de travail et de tension d‚Äôalimentation sont proches d‚Äô√™tre atteintes.
    <br>
    L'industrie a trouv√© une parade simple √† ces probl√®mes, tout du moins √† court terme. L‚Äôid√©e est de multiplier les unit√©s de traitement. L‚Äôint√©r√™t imm√©diat est de r√©soudre le probl√®me de la limite en fr√©quence. Sch√©matiquement, du point de vue de la consommation en √©nergie, il est pr√©f√©rable d‚Äôavoir 2 processeurs fonctionnant √† 2 GHz plut√¥t qu‚Äôun seul fonctionnant √† 4 GHz. La puissance de calcul effective est la m√™me, mais la consommation en √©nergie inf√©rieure pour la premi√®re configuration. C‚Äôest pour cette raison qu‚Äô√† partir des ann√©es 2000, les microprocesseurs ont vu leur nombre de c≈ìurs (ou unit√© de traitement) augmenter. Aujourd‚Äôhui, le nombre de c≈ìurs avoisine 20 c≈ìurs par processeur, il y en aura plus dans quelques ann√©es. Augmenter le nombre de c≈ìurs dans un processeur a aussi une limite, qui est la bande passante entre la m√©moire et le processeur. Tous les c≈ìurs d‚Äôun microprocesseur partagent un m√™me bus pour transf√©rer les informations entre la m√©moire et le microprocesseur.

    ![Les diff√©rents caches d'un microprocesseur](../img/threads_microprocesseurs.png){:width="60%"}

    *(Source: Programmation concurrente (Ma√Ætrisez le traitement de vos donn√©es en Java) - Laurent Joyeux - Collection Epsilon, 2017)*

    <br>
    Si tous les c≈ìurs fonctionnent avec la m√™me charge de travail, la bande passante par c≈ìur est la bande passante totale divis√©e par le nombre de c≈ìurs. Plus le nombre de c≈ìurs est important, et plus les c≈ìurs auront tendance √† attendre les donn√©es. Pour contourner le probl√®me, les microprocesseurs se voient dot√©s d‚Äôune m√©moire cache unifi√©e aux diff√©rents c≈ìurs. La m√©moire cache s‚Äôintercale entre le microprocesseur et la m√©moire principale. La m√©moire cache r√©duit les √©changes avec la m√©moire principale en maintenant une petite partie des donn√©es de la m√©moire principale dans le cache. Une synchronisation des donn√©es est faite entre le cache et la m√©moire principale pour garder la coh√©rence des donn√©es. La m√©moire cache a aussi le bon go√ªt d‚Äô√™tre beaucoup plus rapide que la m√©moire principale. La m√©moire cache limite les √©changes entre le microprocesseur et la m√©moire principale, dans le cas id√©al, les √©changes se feront principalement entre le cache et le microprocesseur.
    <br>
    Pour augmenter la bande passante entre le microprocesseur et la m√©moire principale, une parade consiste √† multiplier le nombre de bus entre le microprocesseur et la m√©moire, c‚Äôest le cas pour les microprocesseurs r√©cents.
    <br>
    L‚Äôav√®nement des [microprocesseurs multic≈ìurs](https://fr.wikipedia.org/wiki/Microprocesseur_multi-c%C5%93ur){:target="_blank"} ne fait que r√©soudre partiellement le probl√®me li√© aux limites actuelles. Reste que l‚Äôexploitation d‚Äôune puissance de calcul r√©partie entre diff√©rents c≈ìurs suppose d‚Äô√©crire des logiciels pouvant tirer parti de ces microprocesseurs. C‚Äôest un des objets de la programmation concurrente. √ätre capable d‚Äô√©crire un logiciel dans un environnement multiprocesseur. Les multiprocesseurs permettent d‚Äôavoir des environnements o√π diff√©rents programmes sont ex√©cut√©s simultan√©ment. Dans un environnement monoc≈ìur, les programmes seront, au mieux, ex√©cut√©s l‚Äôun apr√®s l‚Äôautre de mani√®re exclusive. Ce qui impose plus de rigueur d‚Äô√©criture dans un environnement multic≈ìur...

#### Synth√®se

Le besoin d'accro√Ætre la performance du processeur et la limite mat√©rielle d√ªe au silicium, ont conduit √† l'augmentation des unit√©s de traitement d'un microprocesseur.

**Cons√©quences:**

- Cache interne aux unit√©s de traitements
- Mise √† jour p√©riodique du cache des coeurs avec la m√©moire centrale. **Cette mise √† jour est effectu√©e par l'OS et √©chappe au programmeur.**
- Partage du m√™me bus pour transf√©rer les informations entre la m√©moire et le microprocesseur, induisant des temps de latence.

La plus grande implication est le besoin au niveau applicatif de forcer la synchronisation avec la m√©moire centrale pour garder tous les threads inform√©s de l'√©tat des variables partag√©es.

![Les diff√©rents caches d'un microprocesseur](../img/threads_volatile.png)

**En java, cela passe par l'utilisation du mot cl√© [volatile](#volatile)**

### Environnement multiprocesseur (multi-coeur)

Le premier syst√®me multiprocesseur commercial, le CDC 6600, a √©t√© introduit en 1964

- Plusieurs processeurs physiques. 
- Plusieurs processus peuvent s'ex√©cuter simultan√©ment, chacun sur un processeur diff√©rent (Vrai parall√©lisme)

==> les serveurs, les supercalculateurs et les applications qui n√©cessitent des performances √©lev√©es


### Environnement monothread√©

**Un processus principal = 1 thread**

Si une application monothread√©e tourne dans un environnement multiprocesseur, le syst√®me ne sera pas exploit√© √† son plein potentiel. Comment r√©gler ce probl√®me...  *c'est possible avec les applications multithread√©s*.


### Environnement multithread√©

**Un processus principal et plusieurs fourches**

**[Thread](https://en.wikipedia.org/wiki/Thread_(computing)){:target="_blank"} = fil d'ex√©cution de code, √† l'int√©rieur d'un processus, et qui a la possibilit√© d'√™tre ordonnanc√©.**

- Un programme multithread√© profite des capacit√©s multicoeurs du microprocesseur et du parall√©lisme des t√¢ches.

- chacun thread dispose d'une pile et d'un pointeur de programme

**Attention:** Remarquez qu'une application multithread√©e peut bien tourner dans un environnement monoprocesseur (*avec la pr√©sence de coeur logique*).


### Processus et Threads

Ce qu'il faut retenir: 

- Tout processus a un thread principal,
depuis lequel d‚Äôautres threads peuvent √™tre lanc√©s, dans le cas d'une application multi-thread.

- les threads partagent le m√™me espace d'adressage que le processus qui les a lanc√©s. Cela permet aux threads d'acc√©der aux m√™mes donn√©es et aux m√™mes ressources.


Maintenant que nous savions ce que c'est qu'un thread et un processus sans entrer dans les d√©tails de leurs [cycles de vie](https://fr.wikipedia.org/wiki/Processus_(informatique)){:target="_blank"}, laissez moi vous pr√©senter le Big Boss üòé au niveau du syst√®me d'exploitation qui g√®re tous processus et leurs fils (threads). Le syst√®me d'exploitation peut utiliser diff√©rentes strat√©gies d'allocation des threads aux c≈ìurs pour optimiser l'utilisation des ressources mat√©rielles gr√¢ce au scheduler et nous verrons que cela peut poser quelques probl√®mes lors de l'ex√©cution des programmes multithread√©s.

### Le Scheduler

C'est le chef d'orchestre, un composant logiciel du syst√®me d'exploitation. C'est lui qui d√©cide quel processus (ou thread) a acc√®s √† quelle ressources, quand, comment, pendant combien de temps. Il fait aussi pas mal d'autres choses...

**Ce qui nous int√©resse :**

- le scheduler maintient une liste de processus et de threads √† faire tourner;
- il d√©cide - √† une fr√©quence assez √©lev√©e - de leur donner la main √† tour de r√¥le;
- simplement il faut bien r√©aliser qu'√† ce stade, ce que manipule le scheduler, c'est essentiellement du code binaire, tr√®s proche du processeur, apr√®s toutes les phases de compilation et optimisation.

Pour y arriver il doit adopter une strat√©gie. C'est ce que nous appellons l'ordonnancement. Les deux grandes familles d'ordonnancement sont pr√©sent√©es ci-dessous.

### Les types d'ordonnancement

#### Ordonnancement collaboratif

- les t√¢ches ne sont pas interruptibles: elles rendent la main lorsqu'elles ont fini ou lors de certains appels syst√®mes particuliers.

- Les t√¢ches critiques sont prot√©g√©es.

==> MsDos et Windows 3.1 utilisaient un ordonnancement collaboratif

==> Windows 95, 98 utilisaient un mode collaboratif pour certaines t√¢ches.

ü§ì Que se passe t'il lorsqu'une t√¢che entre dans une boucle infinie ou dure trop longtemps dans ce type d'ordonnancement ?

üò≤ je vous laisse deviner.

#### Ordonnancement pr√©emptif

- Le syst√®me peut interrompre une t√¢che √† tout moment *pour switcher √† un autre thread*

- Le syst√®me n'est pas bloqu√© par certaines t√¢ches trop longues

- Mais cela pose probl√®me pour les t√¢ches critiques qui ne doivent pas √™tre interrompues.

==> Windows NT, XP et suivants, Unix, Linux, MacOs utilisent un ordonnancement pr√©emptif

Vous auriez deviner, nos syst√®mes d'exploitations modernes utisent l'ordonnonancement pr√©emptif. Cependant l'ordonnancement collaboratif est d'actualit√© dans certains contexte.

ü§î Et comment le scheduler op√®re le basculement entre t√¢ches.

### Le context switches

*(Cette section est extrait du FUN Mooc: Les fondamentaux aux concepts avanc√©s du language - Semaine 8)*

Tr√®s bonne question.

L'instant o√π le scheduler d√©cide de suspendre l'ex√©cution d'un processus - ou thread - pour donner la main √† un autre, s'appelle un *context switch*; on parle de *process switch* lorsqu'on passe d'un processus √† un autre, et de task switch ou *thread switch* lorsqu'on passe d'un thread √† un autre √† l'int√©rieur d'un processus.

Le point important pour nous, c'est que le scheduler est un morceau de code g√©n√©rique, il fait donc son travail de mani√®re neutre pour tous les processus ou threads, ind√©pendamment du langage par exemple, ou du domaine d'application; et que le d√©coupage du temps en slots allou√©s aux diff√©rents joueurs se fait bien √©videmment sur la base des instuctions √©l√©mentaires du processeur - ce qu'on appelle les *cycles*.

ü•± Tu veux en venir o√π avec toutes ces informations ?

**Ph√©nom√®ne g√©n√©ral**

Le probl√®me principal ici est li√© √† l'absence de contr√¥le, par le programmeur, sur les context switchings; et du coup ceux-ci peuvent intervenir √† n'importe quel moment. Cela cr√©e parfois de mauvaises surprises.

De mani√®re g√©n√©rale :

- dans un langage de programmation un tout petit peu √©volu√©, un fragment de code (m√™me r√©duit √† une instruction *i++; --i; ...*) se traduit presque toujours en plusieurs instructions binaires pour le processeur

- pour que le programme fonctionne correctement dans un mode multi-thread, certains fragments de code (*permutation, virement bancaire ...*), et notamment ceux qui acc√®dent √† de la m√©moire partag√©e, doivent √™tre ex√©cut√©s de fa√ßon atomique (c-√†-d ne pas √™tre interrompus en plein milieu par le scheduler)

- et sans aide du programmeur, le scheduler n'a aucun moyen de savoir o√π, dans le flot d'instruction binaires, il est l√©gitime ou pas de faire un context switching.

**Solutions**

Pour rendre la programmation par thread utilisable en pratique, il faut lui adjoindre des m√©canismes, accessibles au programmeur, pour rendre explicite ce type de probl√®me.

La notion la plus simple de ces m√©canismes est celle de *verrou* pour impl√©menter une *exclusion mutuelle*.

**En Java, cela passe par l'utilisation du mot cl√© synchronized.**. D'autres m√©chanismes existent comme les s√©maphores que nous aborderons un peu plus loin.


### R√©sum√©

Le besoin de faire de la programmation parall√®le et d'exploiter les potentialit√©s des nouvelles machines ont conduit √† l'utilisation des threads. Cependant cela implique la gestion de la synchronisation des ressources et variables partag√©es (*avec des m√©canismes de programmation: mots cl√©s volatile et synchronized en java*) afin d'√©viter les probl√®mes de: deadlock, race condition, starvation, dormancy ... Des pistes de r√©solutions de ces probl√®mes seront discut√©es un peu plus loin.

## Ressource et zone critique

### Ressource

Entit√© dont un thread ou un processus a besoin pour fonctionner

- ressource mat√©rielle (p√©riph√©riques, processeur)
- ressource logicielle (variables)

### Section critique

Partie d‚Äôun programme dont l‚ÄôexeÃÅcution de doit pas s‚Äôentrelacer avec d‚Äôautres programmes.

Une fois qu‚Äôune taÃÇche y entre, il faut lui permettre de terminer cette section sans permettre aÃÄd‚Äôautres
taÃÇches de travailler sur les meÃÇmes donneÃÅes.

### Attentes passive et active

- **Attente active**: impl√©ment√©e avec une <span class="span-hightlight">boucle</span>, le thread requ√™te en boucle l'acc√®s √† la ressource jusqu'au son obtention. Cette attente est gourmande en CPU.

- **Attente passive**: le thread lib√®re le CPU en attendant que la ressource ne soit disponible donnant ainsi la chance √† d'autre thread de tenter leur chance. Impl√©menter gr√¢ce au m√©canisme de <span class="span-hightlight">wait()</span>;

## M√©canisme classique de synchronization

### Volatile

**1. Utilit√© de volatile**: L'utilisation du mot cl√© volatile force l'√©criture de la valeur d'une variable en m√©moire ainsi que sa relecture. Si une variable n'est pas partag√©e entre plusieurs threads, il n'est pas n√©cessaire d'utiliser le mot-cl√© volatile.

**2. Garantie de lisibilit√©**: Le mot cl√© volatile ne r√©alise aucune op√©ration pour garantir la gestion des acc√®s concurrents : elle offre juste une garantie sur la visibilit√©.

**3. Utilisation**: Le mot cl√© volatile s'utilise sur la d√©claration d'une variable. Il n'est pas possible de l'utiliser sur une m√©thode ou une classe. L‚Äôutilisation de volatile n‚Äôa de sens que sur les types basiques primaires *(boolean, byte, char, short, int, long, float et double)*. L'utilisation de volatile directement sur l'objet n'a pas toujours un effet aussi pr√©visible ou souhaitable. Cela est d√ª au fait que volatile garantit la visibilit√© des changements de la r√©f√©rence √† l'objet, mais pas n√©cessairement des changements internes √† l'objet lui-m√™me. 

**5. Atomicit√© des instructions complexes**: Volatile ne garantit pas l'atomicit√© des op√©rations complexes.

**6. Acc√®s concurrent lecture/√©criture**: En acc√®s concurrent √† une variable volatile, une demande de lecture ne sera accord√©e qu'une fois l'op√©ration d'√©criture en cours termin√©e.

Pour des op√©rations atomiques sur des objets complexes, Java propose d'autres m√©canismes tels que les verrous (synchronized) ou l'utilisation de classes du package <span class="span-hightlight">java.util.concurrent</span>. Ces m√©canismes garantissent √† la fois la visibilit√© des changements et l'atomicit√© des op√©rations complexes. 

Exemple d'utilisation de volatile:

``` java linenums="1" hl_lines="3 6 12"
public class Foo extends Thread{

    private volatile boolean close = false;

    public void run(){
        while(!close){
            // do work
        }
    }

    public void close(){
        close = true;
    }

}
```

### Synchronized

Le mot cl√© synchronized :

- contr√¥le les modifications de variables partag√©es au sein d'une zone critique. Cela assure qu' √† chaque instant, un seul thread peut ex√©cuter et modifier des variables dans zone critique les autres threads attendront leur tour.

- permet de demander l'acquisition d'un moniteur

**Les trois mani√®res d'utiliser synchronized sont mis en √©vidence**

``` java linenums="1" hl_lines="7 14 23"
public class Bridge {

    private Object key =  new Object() ;

    // m√©thode statique synchronis√©e, le param√®tre de synchronisation est 
    // l'objet Bridge.class
    public static synchronized boolean getCapacity() {
      
       // corps de la m√©thode
    }

    // m√©thode non statique synchronis√©e, le param√®tre de synchronisation est
    // l'objet this
    public synchronized boolean enter() {
      
       // corps de la m√©thode
    } 
   
    public boolean getout() {
      
       // synchronization sur l'objet key
       // on peut aussi synchroniser sur l'objet this
       synchronized(key) {
      
          // bloc synchronis√©
       }
    }
}
```

### Exemple de la classe singleton

``` java linenums="1" hl_lines="4 9"
public class Singleton {

    // volatile variable
    public static volatile Singleton _instance ;

    public  getInstance() {
        if(_instance == null){
            synchronized(Singleton.class){
                if(_instance == null){
                    _instance = new Singleton();
                }
            }
        }
      
       return _instance;
    }
}
```

- Le *mot-cl√© volatile est appliqu√© √† la r√©f√©rence de l'instance unique du Singleton*, et non directement √† l'objet complexe lui-m√™me. C'est cette r√©f√©rence qui doit √™tre garantie comme visible entre les threads. 

- Cette approche, appel√©e <span class="span-hightlight">Double-Checked Locking with Volatile</span>, vise √† optimiser les performances en √©vitant le co√ªt du verrouillage √† chaque appel de la m√©thode getInstance, tout en garantissant une initialisation s√ªre dans un environnement multithread√© gr√¢ce √† l'utilisation de volatile. 


## Strat√©gies avanc√©es de synchronisation

Les mutex et les s√©maphores sont des m√©canismes de synchronisation utilis√©s dans la programmation concurrente pour assurer un acc√®s s√©curis√© aux ressources partag√©es entre plusieurs threads.

### Mutex

Un mutex (mutual exclusion) signifie que l'acc√®s √† la ressource est mutuellement exclusif pour les threads.

#### Exemple en Java

```java linenums="1" hl_lines="7 11"
public class ExempleMutex {

    // Le verrou ou mutex
    private final Lock mutex = new ReentrantLock();

    public void methodeCritique(){
        mutex.lock(); // P(mutex) : entr√©e en section critique
        try{
            // Section critique : acc√®s s√©curis√© √† la ressource partag√©e
        } finally{
            mutex.unlock(); // V(mutex): sortie de la section critique
        }
    }
}
```

Pour le mutex, le compteur est 1.

- l'op√©ration **P** (*proberen*, signifiant "essayer" en n√©erlandais) d√©cr√©mente le compteur;
- l'oparation **V** (*verhogen*, signifiant "augmenter" en n√©erlandais) l'incr√©mente

#### Pseudo impl√©mentation id√©ale d'un mutex

```linenums="1" hl_lines="4 11 15 17"
int libre = 1;
fifo liste_attente;

lock(){  // synchronized
    while(1){
        if(libre){
            libre = 0;
            return;
        }
        liste_attente.ajouter(thread_courant());
        wait(); // Met en attente le thread courant
    }
}

unlock(){ // synchronized
    if(liste_attente.non_vide()){
        signal(liste_attente.retirer())
    }else{
        libre = 1;
    }
}
```

### S√©maphore

Un s√©maphore est un m√©canisme plus g√©n√©ral que le mutex et peut √™tre utilis√© pour contr√¥ler l'acc√®s √† un nombre fixe de ressources simultan√©ment.

Pour contr√¥ler l'acc√®s √† un fichier, un s√©maphore peut √™tre utilis√© pour compter le nombre de threads qui acc√®dent au fichier. Lorsque le nombre de threads atteint un certain seuil, le s√©maphore peut √™tre utilis√© pour bloquer les nouveaux threads qui tentent d'acc√©der au fichier.

```java linenums="1" hl_lines="7 11"
public class File {

    // S√©maphore initialis√© avec un compteur de 3
    private final Semaphore sem = new Semaphore(3); // limite √† 3 jetons

    public void open(){
        sem.acquire(); // P op√©ration
        try{
            // Section critique : acc√®s s√©curis√© √† la ressource partag√©e
        } finally{
            sem.release(); // V op√©ration
        }
    }
}
```

Dans cet exemple, le s√©maphore est initialis√© avec une limite de 3. Trois threads peuvent acqu√©rir le s√©maphore simultan√©ment, mais les suivants doivent attendre qu'au moins un thread lib√®re le s√©maphore en ex√©cutant l'op√©ration release.

### Mutex - Moniteur - Semaphore

üìÑ [Diff√©rence entre Mutex - Moniteur - Semaphore](https://codegym.cc/fr/groups/posts/fr.220.difference-entre-un-mutex-un-moniteur-et-un-semaphore){:target="_blank"}

## Probl√®mes (Liveness)

### Deadlock ‚ùå

Un deadlock est une situation dans laquelle deux ou plusieurs threads sont bloqu√©s l'un l'autre, emp√™chant chacun de terminer son ex√©cution. Cela se produit lorsque chaque thread d√©tient une ressource dont l'autre thread a besoin pour continuer √† s'ex√©cuter.

!!! tip "Pr√©ventions"
    Voici quelques conseils pour pr√©venir les deadlocks :

    - **Utilisez des m√©canismes de synchronisation appropri√©s**. Les m√©canismes de synchronisation comme les mutex et les s√©maphores peuvent √™tre utilis√©s pour contr√¥ler l'acc√®s aux ressources partag√©es. Il est important d'utiliser le m√©canisme de synchronisation appropri√© pour la situation.
    - **√âvitez les verrous circulaires**. Un verrou circulaire se produit lorsqu'un thread d√©tient un verrou sur une ressource qui est d√©tenue par un autre thread qui d√©tient un verrou sur la premi√®re ressource. Les verrous circulaires peuvent entra√Æner des deadlocks.
    - **Planifiez les threads de mani√®re efficace**. Le syst√®me d'exploitation peut d√©cider de mettre un thread en veille si d'autres threads sont plus prioritaires. Pour √©viter cela, planifiez les threads de mani√®re √† ce que les threads les plus importants soient ex√©cut√©s en premier.

### Race condition ‚ùå

Une race condition est une condition dans un programme multithread o√π le r√©sultat de l'ex√©cution du programme d√©pend de l'ordre dans lequel les threads s'ex√©cutent. Les race conditions peuvent entra√Æner des erreurs, des donn√©es corrompues ou un comportement inattendu.

Une race condition peut se produire lorsqu'un ou plusieurs threads acc√®dent √† la m√™me variable ou ressource partag√©e. Si les threads acc√®dent √† la variable ou √† la ressource en m√™me temps, le r√©sultat de l'ex√©cution du programme peut √™tre diff√©rent de celui qui serait obtenu si les threads s'ex√©cutaient s√©quentiellement.

Voici quelques exemples de race conditions :

- Deux threads qui tentent d'√©crire la m√™me valeur dans une variable partag√©e.
- Deux threads qui tentent de lire la m√™me variable partag√©e sans utiliser de m√©canisme de synchronisation.
- Deux threads qui tentent de supprimer un √©l√©ment d'une liste partag√©e.

Les race conditions peuvent √™tre difficiles √† diagnostiquer et √† d√©boguer. Il est important de comprendre les causes des race conditions et les mesures √† prendre pour les pr√©venir.

!!! tip "Pr√©ventions"
    - Utilisez des variables ou des ressources partag√©es de mani√®re exclusive.

### Starvation ‚ùå

Un thread est incapable d'acc√©der √† des ressources partag√©es pendant une p√©riode prolong√©e, ce qui emp√™che le thread de s'ex√©cuter et de terminer ses t√¢ches. Cela peut se produire lorsqu'un thread a une priorit√© plus faible que les autres threads ou lorsque d'autres threads utilisent constamment les ressources partag√©es.

Voici quelques exemples de conditions qui peuvent entra√Æner de la starvation :

- Un thread avec une priorit√© faible a constamment acc√®s √† des ressources partag√©es.
- Plusieurs threads acc√®dent constamment √† la m√™me ressource partag√©e, emp√™chant d'autres threads d'y acc√©der.
- Un thread utilise une boucle infinie pour acc√©der √† une ressource partag√©e, emp√™chant d'autres threads d'y acc√©der. (*Attente active*)

!!! tip "Pr√©ventions"
    - Utilisez des politiques de planification qui accordent des ressources aux threads en fonction de leur priorit√©.
    - Utilisez des m√©canismes de synchronisation (mutex, semaphores) pour emp√™cher les threads d'acc√©der aux ressources partag√©es lorsqu'elles ne sont pas disponibles.
    - √âvitez d'utiliser des boucles infinies pour acc√©der aux ressources partag√©es.

### Dormancy ‚ùå

Un thread dormant est un thread qui a √©t√© plac√© dans un √©tat d'attente par le syst√®me d'exploitation. Cela signifie que le thread n'ex√©cute pas de code actuellement, mais attend toujours qu'un √©v√©nement sp√©cifique se produise avant de pouvoir reprendre l'ex√©cution. Trop de dormance est un probl√®me

!!! info "Les raisons de la dormance"
    Il existe plusieurs raisons pour lesquelles un thread peut √™tre plac√© dans un √©tat dormant :

    - **En attente de la fin d'une op√©ration d'E/S** : Lorsqu'un thread √©met une demande d'E/S, telle que la lecture d'un fichier ou d'une prise de socket r√©seau, le thread est g√©n√©ralement plac√© dans un √©tat dormant jusqu'√† ce que l'op√©ration d'E/S soit termin√©e. C'est parce que le thread ne peut pas continuer √† s'ex√©cuter tant que les donn√©es demand√©es ne sont pas disponibles.

    - **En attente d'un √©v√©nement de synchronisation** : Les threads peuvent √©galement √™tre plac√©s dans un √©tat dormant pour attendre un √©v√©nement de synchronisation, tel qu'un s√©maphore ou un mutex pour devenir disponible. Cela est utilis√© pour contr√¥ler l'acc√®s aux ressources partag√©es et garantir qu'un nombre multiple de threads n'acc√®de pas √† la m√™me ressource en m√™me temps.

    - **En attente de la survenue d'une condition sp√©cifique** : Les threads peuvent √©galement √™tre plac√©s dans un √©tat dormant pour attendre la survenue d'une condition sp√©cifique. Cela est souvent utilis√© pour impl√©menter des d√©lais d'expiration ou d'autres formes d'ex√©cution conditionnelle.

!!! tip "Pr√©ventions"
    - D√©finir un d√©lai de **l'attente passive** en pr√©cisant en java le temps d'attente du thread au bout lequel il se r√©veillera sans aucun √©v√©nement externe

    ```java
    wait(3000); // Environ 3s
    ```

    - S'assurez que le thread ne restera pas endormi un *wait()* doit √™tre suivi d'un *notify()* ou d'un *notifyAll()*

## Aller plus loin ‚ùå

### API java de gestion de la concurrence

### Programmation asynchrone

## Liens utiles

- üìÑ [Sp√©cification JAVA SE threads et locks](https://docs.oracle.com/javase/specs/jls/se8/html/jls-17.html#jls-17.4.1){:target="_blank"}

- üìÑ [What is the volatile keyword useful for](https://stackoverflow.com/questions/106591/what-is-the-volatile-keyword-useful-for){:target="_blank"}

- üìÑ Programmation concurrente (Ma√Ætrisez le traitement de vos donn√©es en Java Java) - Laurent Joyeux - Collection Epsilon, 2017

- :fontawesome-brands-youtube:{ .youtube } Programmation concurrente - Multithreading et traitement d'informations en Java (ENI) de Thomas Broussard

- :fontawesome-brands-youtube:{ .youtube } [Probl√®mes de synchronisation](https://www.youtube.com/watch?v=l_dnpUkkaSg){:target="_blank"}

- :fontawesome-brands-youtube:{ .youtube } [Probl√®me des lecteurs et r√©dacteurs](https://www.youtube.com/watch?v=B2xijT1ULHw){:target="_blank"} 

- :fontawesome-brands-youtube:{ .youtube } [Probl√®me des philosophes](https://www.youtube.com/watch?v=Qmb3iGf9HJg){:target="_blank"} 

- :fontawesome-brands-youtube:{ .youtube } [Probl√®me des producteurs et consommateurs](https://www.youtube.com/watch?v=SJDejntCGSM){:target="_blank"}

- üìÑ [Probl√®me de famine](https://fr.wikipedia.org/wiki/Famine_(informatique)){:target="_blank"}

- üìÑ [Blog Paumard](https://blog.paumard.org/cours/java-api/chap05-concurrent-synchronisation.html){:target="_blank"}


- üìÑ [Handout programmation concurrente](https://p-fb.net/licence3/prog_concurrente/cours/handout_programmation_concurrente_2022_2023.pdf){:target="_blank"}




